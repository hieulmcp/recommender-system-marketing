##########################################################################################################################################################
# TH∆Ø VI·ªÜN
##########################################################################################################################################################
import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from PIL import Image

import pickle
#########################################################################################################################################################
# COLLABORATIVE FILTERING
#########################################################################################################################################################
import lib.step15_collaborative_filtering as clf

def pyspark_collaborative_filtering(fea_customer_id_number):
    #B∆∞·ªõc 1: Create the SparkSession Object
    spark = clf.get_spark_session(title='Recommender Systems - H·ªá th·ªëng ƒë·ªÅ xu·∫•t')
    #B∆∞·ªõc 2: Read the Dataset: Chung ta khi load v√† ƒë·ªçc d·ªØ li·ªáu v·ªõi Spark ph·∫£i s·ª≠ d·ª•ng dataframe.
    file_path = 'data_analysis/data_merge.csv'
    df = clf.load_data(file_path=file_path)
    lst = ['fea_item_id','fea_name','fea_customer_id','fea_rating_y','image','url','brand','list_price','price','rating']
    data_sub = clf.select_data(df=df, lst=lst)
    #B∆∞·ªõc 3: Exploratory Data Analysis: Kh√°m ph√° d·ªØ li·ªáu b·ªõi v√¨ xem x√©t d·ªØ li·ªáu, ƒëi·ªÅu ki·ªán d·ªØ li·ªáu v√† ƒë·∫øm xem c√≥ bao nhi·ªÅu m√£ h√†ng, bao nhi√™u sao ƒë√°nh gi√°.
    #B∆∞·ªõc 4: Feature Engineering: Ch√∫ng t√¥i s·∫Ω convert nh·ªØng column categorical sang numerical values using StringIndexex
    indexed = clf.feature_engineering_stringIndexer(data_sub=data_sub, inputCol="fea_name", outputCol="title_new")
    #B∆∞·ªõc 5: Splitting the Dataset: Chung ta c√≥ th·ªÉ so s√°nh d·ªØ li·ªáu x√¢y d·ª±ng m√¥ h√¨nh ƒë·ªÅ xu·∫•t, chung c√≥ th·ªÉ chia d·ªØ li·ªáu theo d·ªØ li·ªáu training v√† test v√† chung ta c√≥ th·ªÉ chia trong kho·∫£ng 75 ƒë·∫øn 25 ch·ªâ s·ªë train mode v√† test accuracy
    train, test =  clf.random_split(data_sub=data_sub, randoms = [0.75,0.25])
    train.count(), test.count()
    #B∆∞·ªõc 6: Build and Train Recommender Model: Ch√∫ng ta c√≥ th·ªÉ import ALS th∆∞ vi·ªán Pyspark machine learning v√† x√¢y d·ª±ng m√¥ h√¨nh training d·ªØ li·ªáu v√† c√≥ r·∫•t nhi·ªÅu parameter nh∆∞ng c√≥ tuned c·∫£i thi·ªán hi·ªáu su·∫•t m√¥ h√¨nh trong ƒëo: c√≥ 2 para quan tr·ªçng ƒë√≥ l√†:  nonnegative =‚ÄòTrue‚Äô: N√≥ kh√¥ng th√™m negative ratings in recommendations v√† coldStartStrategy=‚Äòdrop‚Äô to prevent any NaN ratings predictions
    rec_model = clf.als_model(train=train, maxIter=15, userCol='fea_customer_id',itemCol='fea_item_id',ratingCol='fea_rating_y', nonnegative=True, coldStartStrategy="drop")
    #B∆∞·ªõc 7: Predictions and Evaluation on Test Data: Ho√†n th√†nh 1 ph·∫ßn b√†i t·∫≠p l√† ki·ªÉm tra hi·ªáu qu·∫£ c·ªßa m√¥ h√¨nh ho·∫∑c test d·ªØ li·ªáu v√† ch√∫ng ta s·ª≠ d·ª•ng c√°c h√†m l√†m d·ª± ƒëo√°n tr√™n t·∫≠p test data v√† RegressionEvaluate ƒë·ªÉ check the RMSE value c·ªßa t·∫≠p d·ªØ li·ªáu
    predicted_ratings = clf.transform_test(rec_model = rec_model, test = test)
    rmse = clf.evaluator_als(predicted_ratings)
    #B∆∞·ªõc 8: Recommend Top item That Active User Might Like: Sau khi ki·ªÉm tra hi·ªÉu qu·∫£ v·ªÅ m√¥ h√¨nh v√† tuning the hyperparameters v√† ch√∫ng ta c√≥ th·ªÉ duy chuy·ªÉn ƒë·ªÉ xu·∫•t theo top items t·ªõi user id ƒë√≥ v√† h·ªç c√≥ th·ªÉ nh√¨n v√† th√≠ch
    fea_customer_id_number = fea_customer_id_number
    recommendations = clf.recomend_top_item(data_sub, rec_model, fea_customer_id_number, fea_item_id = 'fea_item_id',\
        fea_customer_id='fea_customer_id',how='left', \
        lst_ = ['fea_item_id','fea_name','fea_customer_id','fea_rating_y','image','url','brand','list_price','price','rating'])
    recommendations_pandas = recommendations.toPandas()
    
    dir_file2 = "data_analysis/ProductRaw_processing_2.csv"
    df2 = pd.read_csv(dir_file2)
    df2 = df2.rename(columns={'fea_product_id': 'fea_item_id'})
    data = pd.merge(recommendations_pandas, df2, on ='fea_item_id', how ='inner')
    lst2 = ['fea_customer_id', 'prediction', 'fea_item_id','name','description', 'rating', 'price', 'list_price', 'brand','group', 'url', 'image' ]
    data_1 = data[lst2]
    data_2 = data_1.head(10)
    return data_2, rmse
    
dir_file3 = "data_analysis/fea_customer_id.csv"
df3 = pd.read_csv(dir_file3)



###########################################################################################################################################################
# CONTENT BASED FILTERING
###########################################################################################################################################################

data_content=pickle.load(open('item_list.pkl','rb'))
vector=pickle.load(open('similarity.pkl','rb'))

def recommend(content):
    content=data_content[data_content.fea_name==content].index.values[0]
    
    df_recommnend=pd.DataFrame(enumerate(vector[content])).drop(0,axis='columns').sort_values(by=1,ascending=False)
    df_recommnend['Names']=list(map(lambda x: str(np.squeeze(data_content[data_content.index==x]['fea_name'].values)),df_recommnend.index.values))
    df_recommnend['id']=list(map(lambda x: int(np.squeeze(data_content[data_content.index==x]['fea_item_id'].values)),df_recommnend.index.values))

    df_recommnend['url']=list(map(
        lambda x: np.squeeze(data_content[data_content.index==x]['url'].values),df_recommnend.index.values))
    df_recommnend['image']=list(map(
        lambda x: np.squeeze(data_content[data_content.index==x]['image'].values),df_recommnend.index.values))
    df_recommnend['rating']=list(map(
        lambda x: int(np.squeeze(data_content[data_content.index==x]['rating'].values)),df_recommnend.index.values))
    df_recommnend['price']=list(map(
        lambda x: int(np.squeeze(data_content[data_content.index==x]['price'].values)),df_recommnend.index.values))
    df_recommnend['brand']=list(map(
        lambda x: np.squeeze(data_content[data_content.index==x]['brand'].values),df_recommnend.index.values))
    df_recommnend = df_recommnend.reset_index()
    df_recommnend = df_recommnend.drop(['index'], axis=1)
    
    return df_recommnend

###########################################################################################################################################################
# STREAMLIT
###########################################################################################################################################################
menu = ['Tiki','T·ªïng quan','Gi·ªõi thi·ªáu m√¥ h√¨nh - Content based fitering','Gi·ªõi thi·ªáu m√¥ h√¨nh - Collaborative filtering', 'Th·ª±c hi·ªán b√†i to√°n', 'ƒê·∫ø xu·∫•t d·ª±a tr√™n n·ªôi dung', 'ƒê·ªÅ xu·∫•t d·ª±a tr√™n s·∫£n ph·∫©m', 'K·∫øt lu·∫≠t v√† h∆∞·ªõng ph√°t tri·ªÉn h·ªá th·ªëng ƒë·ªÅ xu·∫•t']
choice = st.sidebar.selectbox('Menu',menu)

if choice == 'Tiki':
    st.markdown("<h1 style='text-align: center; color: Coral;'>TIKI NI·ªÄM T·ª∞ H√ÄO VI·ªÜT NAM - CH√ÄO M·ª™NG ƒê·∫æN H·ªÜ TH·ªêNG TIKI</h1>", unsafe_allow_html=True)
    st.image('picture/tiki.PNG')
    st.markdown("- V·ªõi ph∆∞∆°ng ch√¢m ho·∫°t ƒë·ªông ‚ÄúT·∫•t c·∫£ v√¨ Kh√°ch H√†ng‚Äù, Tiki lu√¥n kh√¥ng ng·ª´ng n·ªó l·ª±c n√¢ng cao ch·∫•t l∆∞·ª£ng d·ªãch v·ª• v√† s·∫£n ph·∫©m, t·ª´ ƒë√≥ mang ƒë·∫øn tr·∫£i nghi·ªám mua s·∫Øm tr·ªçn v·∫πn cho Kh√°ch H√†ng Vi·ªát Nam v·ªõi d·ªãch v·ª• giao h√†ng nhanh trong 2 ti·∫øng v√† ng√†y h√¥m sau TikiNOW l·∫ßn ƒë·∫ßu ti√™n t·∫°i ƒê√¥ng Nam √Å, c√πng cam k·∫øt cung c·∫•p h√†ng ch√≠nh h√£ng v·ªõi ch√≠nh s√°ch ho√†n ti·ªÅn 111% n·∫øu ph√°t hi·ªán h√†ng gi·∫£, h√†ng nh√°i.")
    st.markdown("- Th√†nh l·∫≠p t·ª´ th√°ng 3/2010, Tiki.vn hi·ªán ƒëang l√† trang th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ l·ªçt top 2 t·∫°i Vi·ªát Nam v√† top 6 t·∫°i khu v·ª±c ƒê√¥ng Nam √Å.")
    st.markdown("- Tiki l·ªçt Top 1 n∆°i l√†m vi·ªác t·ªët nh·∫•t Vi·ªát Nam trong ng√†nh Internet/E-commerce 2018 (Anphabe b√¨nh ch·ªçn), Top 50 n∆°i l√†m vi·ªác t·ªët nh·∫•t ch√¢u √Å 2019 (HR Asia b√¨nh ch·ªçn).")
    st.markdown("[Website](https://tiki.vn/)")
    st.write(" ")

elif choice == 'T·ªïng quan':
    st.image('picture/teamwork.jpg')
    st.markdown("<h1 style='text-align: center; color: Coral;'>H·ªÜ TH·ªêNG ƒê·ªÄ XU·∫§T S·∫¢N PH·∫®M CHO NG∆Ø·ªúI D√ôNG</h1>", unsafe_allow_html=True)
    st.write(" ")

    st.markdown("<h2 style='text-align: left; color: Yellow;'>T·ªîNG QUAN H·ªÜ TH·ªêNG ƒê·ªÄ XU·∫§T NG∆Ø·ªúI D√ôNG</h2>", unsafe_allow_html=True)
    st.markdown("<h3 style='text-align: left; color: Aqua;'>1. Gi·ªõi thi·ªáu</h3>", unsafe_allow_html=True)
    st.markdown("- Tiki l√† m·ªôt h·ªá sinh th√°i th∆∞∆°ng m·∫°i 'all in one', trong ƒë√≥ c√≥ tiki.vn, l√† m·ªôt website th∆∞∆°ng m·∫°i ƒëi·ªán t·ª± ƒë·ª©ng top 2 c·ªßa Vietnam v√† top 6 khu v·ª±c ƒê√¥ng Nam √Å")   
    st.markdown("- Tr√™n trang n√†y ƒë√£ tri·ªÉn khai nhi·ªÅu ti·ªán √≠ch h·ªó tr·ª£ n√¢ng cao tr·∫£i nghi·ªám ng∆∞·ªùi d√πng v√† h·ªç mu·ªën x√¢y d·ª±ng nhi·ªÅu ti·ªán √≠ch h∆°n n·ªØa.")
    st.markdown("- Gi·∫£ s·ª≠ c√¥ng ty n√†y ch∆∞a tri·ªÉn khai Recommender System v√† b·∫°n ƒë∆∞·ª£c y√™u c·∫ßu tri·ªÉn khai h·ªá th·ªëng n√†y, b·∫°n s·∫Ω l√†m g√¨?")
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>2. V√¨ sao c√≥ d·ª± √°n n√†o ?</h3>", unsafe_allow_html=True)
    st.markdown("- X√¢y d·ª±ng Recommendation System cho m·ªôt ho·∫∑c m·ªôt s·ªë nh√≥m h√†ng h√≥a tr√™n tiki.vn gi√∫p ƒë·ªÅ xu·∫•t v√† g·ª£i √Ω cho ng∆∞·ªùi d√πng/ kh√°ch h√†ng. => X√¢y d·ª±ng c√°c m√¥ h√¨nh ƒë·ªÅ xu·∫•t")   
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>3. D·ªØ li·ªáu cung c·∫•p</h3>", unsafe_allow_html=True)
    st.markdown("- D·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p s·∫µn g·ªìm c√≥ c√°c t·∫≠p tin: ProductRaw.csv, ReviewRaw.csv ch·ª©a th√¥ng tin s·∫£n ph·∫©m, review v√† rating cho c√°c s·∫£n ph·∫©m thu·ªôc c√°c nh√≥m h√†ng h√≥a nh∆∞ Mobile_Tablet, TV_Audio, Laptop, Camera, Accessory")   
    st.write(" ")
    
    st.markdown("<h3 style='text-align: left; color: Aqua;'>4. ƒê·∫∑t ra y√™u c·∫ßu v·ªõi b√†i to√°n</h3>", unsafe_allow_html=True)
    st.image('picture/compare.png')
    st.markdown("- B√†i to√°n 1: ƒê·ªÅ xu·∫•t ng∆∞·ªùi d√πng v·ªõi content - based filtering")
    st.markdown("- B√†i to√°n 2: ƒê·ªÅ xu·∫•t ng∆∞·ªùi d√πng v·ªõi Collaborative filtering")
    st.write(" ")

elif choice == 'Gi·ªõi thi·ªáu m√¥ h√¨nh - Content based fitering':

    st.markdown("<h1 style='text-align: center; color: Coral;'>CONTENT BASED FILTERING</h1>", unsafe_allow_html=True)
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>1. Nh·ªØng g√¨ content based filtering l√†m ƒë∆∞·ª£c ?</h3>", unsafe_allow_html=True)
    st.image('picture/hay.png')
    st.markdown("- ƒê·ªÅ xu·∫•t c√°c m·ª•c t∆∞∆°ng t·ª± cho ng∆∞·ªùi d√πng m√† ng∆∞·ªùi d√πng ƒë√£ th√≠ch trong qu√° kh·ª© - This type of RS recommends similar items to the users that the user has liked in the past")
    st.markdown("- V√¨ v·∫≠y, to√†n b·ªô √Ω t∆∞·ªüng l√† t√≠nh to√°n ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng gi·ªØa hai m·ª•c b·∫•t k·ª≥ v√† ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t cho ng∆∞·ªùi d√πng d·ª±a tr√™n h·ªì s∆° v·ªÅ s·ªü th√≠ch c·ªßa ng∆∞·ªùi d√πng - So, the whole idea is to calculate a similarity score between any two items and recommended to the user based upon the profile of the user‚Äôs interests")
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>2. Ho·∫°t ƒë·ªông c·ªßa content based filtering nh∆∞ th·∫ø n√†o ?</h3>", unsafe_allow_html=True)
    st.markdown("- B∆∞·ªõc 1: L·ªçc d·ª±a tr√™n n·ªôi dung")
    st.markdown("- B∆∞·ªõc 2: Ch√∫ng ƒë·ªÅ xu·∫•t c√°c m·ª•c t∆∞∆°ng t·ª± d·ª±a tr√™n m·ªôt n·ªôi dung c·ª• th·ªÉ")
    st.markdown("- B∆∞·ªõc 3: H·ªá th·ªëng n√†y s·ª≠ d·ª•ng si√™u d·ªØ li·ªáu n·ªôi dung, ch·∫≥ng h·∫°n nh∆∞ th·ªÉ 1 s·∫£n ph·∫©m c·ª• th·ªÉ, lo·∫°i s·∫£n ph·∫≠m, nh·ªØng n·ªôi dung c·∫ßn t√¨m ki·∫øm v.v. ƒë·ªÉ ƒë∆∞a ra c√°c ƒë·ªÅ xu·∫•t cho ng∆∞·ªùi d√πng")
    st.markdown("- √ù t∆∞·ªüng chung ƒë·∫±ng sau c√°c h·ªá th·ªëng gi·ªõi thi·ªáu n√†y l√† n·∫øu m·ªôt ng∆∞·ªùi th√≠ch m·ªôt m·∫∑t h√†ng c·ª• th·ªÉ, h·ªç c≈©ng s·∫Ω th√≠ch m·ªôt m·∫∑t h√†ng t∆∞∆°ng t·ª± v·ªõi n√≥")
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>3. Similarity Score</h3>", unsafe_allow_html=True)
    st.image('picture/Similarity_Score.png')
    st.markdown("- L√†m th·∫ø n√†o ƒë·ªÉ n√≥ quy·∫øt ƒë·ªãnh m·∫∑t h√†ng n√†o gi·ªëng v·ªõi m·∫∑t h√†ng m√† ng∆∞·ªùi d√πng th√≠ch nh·∫•t ?")
    st.markdown("- Th·ª© nh·∫•t: ·ªû ƒë√¢y ch√∫ng t√¥i s·ª≠ d·ª•ng ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng. N√≥ l√† m·ªôt gi√° tr·ªã s·ªë n·∫±m trong kho·∫£ng t·ª´ 0 ƒë·∫øn 1, gi√∫p x√°c ƒë·ªãnh xem hai m·ª•c t∆∞∆°ng t·ª± nhau ·ªü m·ª©c ƒë·ªô n√†o tr√™n thang ƒëi·ªÉm t·ª´ 0 ƒë·∫øn 1.")
    st.markdown("- Th·ª© hai: ƒêi·ªÉm t∆∞∆°ng t·ª± n√†y thu ƒë∆∞·ª£c khi ƒëo m·ª©c ƒë·ªô gi·ªëng nhau gi·ªØa c√°c chi ti·∫øt vƒÉn b·∫£n c·ªßa c·∫£ hai m·ª•c.")
    st.markdown("- V√¨ v·∫≠y, ƒëi·ªÉm t∆∞∆°ng t·ª± l√† th∆∞·ªõc ƒëo m·ª©c ƒë·ªô gi·ªëng nhau gi·ªØa c√°c chi ti·∫øt vƒÉn b·∫£n nh·∫•t ƒë·ªãnh c·ªßa hai m·ª•c. ƒêi·ªÅu n√†y c√≥ th·ªÉ ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng t√≠nh t∆∞∆°ng t·ª± cosine.")
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>4. Cosine Similarity ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o ?</h3>", unsafe_allow_html=True)
    st.image('picture/Similarity_Score_2.png')
    st.markdown("- Cosine Similarity l√† m·ªôt s·ªë li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒëo l∆∞·ªùng m·ª©c ƒë·ªô t∆∞∆°ng t·ª± c·ªßa c√°c t√†i li·ªáu b·∫•t k·ªÉ k√≠ch th∆∞·ªõc c·ªßa ch√∫ng")
    st.markdown("- V·ªÅ m·∫∑t to√°n h·ªçc, n√≥ ƒëo cosin c·ªßa g√≥c gi·ªØa hai vect∆° ƒë∆∞·ª£c chi·∫øu trong kh√¥ng gian ƒëa chi·ªÅu. S·ª± gi·ªëng nhau v·ªÅ cosin l√† c√≥ l·ª£i v√¨ ngay c·∫£ khi hai item t∆∞∆°ng t·ª± c√°ch xa nhau b·∫±ng kho·∫£ng c√°ch Euclide (do k√≠ch th∆∞·ªõc c·ªßa t√†i li·ªáu), r·∫•t c√≥ th·ªÉ ch√∫ng v·∫´n ƒë∆∞·ª£c ƒë·ªãnh h∆∞·ªõng g·∫ßn nhau h∆°n. G√≥c c√†ng nh·ªè th√¨ ƒë·ªô t∆∞∆°ng ƒë·ªìng cosin c√†ng cao")
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>5. Hi·ªán th·ªâ b·∫£ng d·ªØ li·ªáu c·ªßa b√†i to√°n ?</h3>", unsafe_allow_html=True)
    selected_movie = st.selectbox('L·ª±a ch·ªçn 1 item b·∫•t k·ª≥',(list(data_content.fea_name.values)))
    df_recommnend = recommend(selected_movie)
    test = df_recommnend.astype(str)
    st.dataframe(test)
    

elif choice == 'Gi·ªõi thi·ªáu m√¥ h√¨nh - Collaborative filtering':

    st.markdown("<h1 style='text-align: center; color: Coral;'>COLLABORATIVE FILTERING</h1>", unsafe_allow_html=True)
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>1. Collaborative filtering l√† g√¨ ?</h3>", unsafe_allow_html=True)
    st.image('picture/Collaborative-filtering.jpg')
    st.markdown("- L√† m·ªôt t·∫≠p h·ª£p con c√°c thu·∫≠t to√°n s·ª≠ d·ª•ng r·ªông r√£i ng∆∞·ªùi d√πng v√† m·ª•c kh√°c c√πng v·ªõi x·∫øp h·∫°ng v√† l·ªãch s·ª≠ ng∆∞·ªùi d√πng m·ª•c ti√™u c·ªßa h·ªç ƒë·ªÉ ƒë·ªÅ xu·∫•t m·ªôt m·ª•c m√† ng∆∞·ªùi d√πng m·ª•c ti√™u kh√¥ng c√≥ x·∫øp h·∫°ng")
    st.markdown("- Gi·∫£ ƒë·ªãnh c∆° b·∫£n ƒë·∫±ng sau c√°ch ti·∫øp c·∫≠n n√†y l√† nh·ªØng ng∆∞·ªùi d√πng kh√°c ∆∞a th√≠ch c√°c m·∫∑t h√†ng c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ gi·ªõi thi·ªáu m·ªôt m·∫∑t h√†ng cho ng∆∞·ªùi d√πng ch∆∞a t·ª´ng xem ho·∫∑c ƒë√£ mua h√†ng tr∆∞·ªõc ƒë√≥.")
    st.markdown("- CF kh√°c v·ªõi c√°c ph∆∞∆°ng ph√°p d·ª±a tr√™n n·ªôi dung ·ªü ch·ªó ng∆∞·ªùi d√πng ho·∫∑c b·∫£n th√¢n m·∫∑t h√†ng kh√¥ng ƒë√≥ng vai tr√≤ trong ƒë·ªÅ xu·∫•t m√† l√† c√°ch (x·∫øp h·∫°ng) v√† ng∆∞·ªùi d√πng (ng∆∞·ªùi d√πng) ƒë√°nh gi√° m·ªôt m·∫∑t h√†ng c·ª• th·ªÉ")
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>2. Thu·∫≠t to√°n Collaborative filtering</h3>", unsafe_allow_html=True)
    st.image('picture/thuat_toan.png')
    st.markdown("- C√°c thu·∫≠t to√°n d·ª±a tr√™n m√¥ h√¨nh x√¢y d·ª±ng m·ªôt m√¥ h√¨nh t·ª´ h√†nh vi tr∆∞·ªõc ƒë√¢y c·ªßa ng∆∞·ªùi d√πng, sau ƒë√≥ s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√≥ ƒë·ªÉ ƒë·ªÅ xu·∫•t c√°c m·∫∑t h√†ng cho b·∫•t k·ª≥ ng∆∞·ªùi d√πng n√†o")
    st.markdown("- Ch√∫ng c√≥ hai ∆∞u ƒëi·ªÉm ch√≠nh so v·ªõi c√°c ph∆∞∆°ng ph√°p ti·∫øp c·∫≠n d·ª±a tr√™n b·ªô nh·ªõ: ch√∫ng c√≥ th·ªÉ cung c·∫•p c√°c ƒë·ªÅ xu·∫•t cho ng∆∞·ªùi d√πng m·ªõi v√† ch√∫ng c√≥ th·ªÉ cung c·∫•p c√°c ƒë·ªÅ xu·∫•t t·ª©c th√¨, v√¨ h·∫ßu h·∫øt vi·ªác t√≠nh to√°n ƒë∆∞·ª£c chuy·ªÉn sang giai ƒëo·∫°n x·ª≠ l√Ω tr∆∞·ªõc c·ªßa qu√° tr√¨nh t·∫°o m√¥ h√¨nh. C√°c thu·∫≠t to√°n d·ª±a tr√™n b·ªô nh·ªõ k·∫øt h·ª£p vi·ªác t·∫°o m√¥ h√¨nh v√† c√°c ƒë·ªÅ xu·∫•t t·ª©c th√¨ th√†nh m·ªôt th·ªß t·ª•c duy nh·∫•t")
    st.markdown("- C√°c thu·∫≠t to√°n y·∫øu t·ªë ti·ªÅm ·∫©n gi·∫£i th√≠ch s·ªü th√≠ch c·ªßa ng∆∞·ªùi d√πng b·∫±ng c√°ch m√¥ t·∫£ ƒë·∫∑c ƒëi·ªÉm c·ªßa s·∫£n ph·∫©m v√† ng∆∞·ªùi d√πng v·ªõi c√°c y·∫øu t·ªë ƒë∆∞·ª£c t·ª± ƒë·ªông suy ra t·ª´ ph·∫£n h·ªìi c·ªßa ng∆∞·ªùi d√πng.")
    st.markdown("- ·ªû d·∫°ng c∆° b·∫£n, ph√¢n t√≠ch nh√¢n t·ª≠ ma tr·∫≠n ƒë·∫∑c tr∆∞ng cho c√°c m·∫∑t h√†ng v√† ng∆∞·ªùi d√πng b·∫±ng vect∆° c·ªßa c√°c y·∫øu t·ªë ƒë∆∞·ª£c suy ra t·ª´ c√°c m·∫´u s·ª≠ d·ª•ng m·∫∑t h√†ng. S·ª± t∆∞∆°ng ·ª©ng cao gi·ªØa c√°c y·∫øu t·ªë m·∫∑t h√†ng v√† ng∆∞·ªùi d√πng d·∫´n ƒë·∫øn m·ªôt ƒë·ªÅ xu·∫•t. C√°c ph∆∞∆°ng ph√°p n√†y ƒë√£ tr·ªü n√™n ph·ªï bi·∫øn v√¨ ch√∫ng k·∫øt h·ª£p ƒë·ªô ch√≠nh x√°c c·ªßa d·ª± ƒëo√°n v·ªõi kh·∫£ nƒÉng m·ªü r·ªông t·ªët.")
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>3. Thu·∫≠t to√°n ALS - Alternating Least Squares</h3>", unsafe_allow_html=True)
    st.image('picture/ALS.png')
    st.markdown("- Thu·∫≠t to√°n ALS s·∫Ω ph√°t hi·ªán ra c√°c y·∫øu t·ªë ti·ªÅm ·∫©n gi·∫£i th√≠ch ng∆∞·ªùi d√πng quan s√°t ƒë∆∞·ª£c x·∫øp h·∫°ng m·∫∑t h√†ng v√† c·ªë g·∫Øng t√¨m tr·ªçng s·ªë y·∫øu t·ªë t·ªëi ∆∞u ƒë·ªÉ gi·∫£m thi·ªÉu b√¨nh ph∆∞∆°ng nh·ªè nh·∫•t gi·ªØa x·∫øp h·∫°ng d·ª± ƒëo√°n v√† th·ª±c t·∫ø.")
    st.write(" ")

elif choice == 'Th·ª±c hi·ªán b√†i to√°n':

    st.markdown("<h1 style='text-align: center; color: Coral;'>C√ÅC B∆Ø·ªöC TH·ª∞C HI·ªÜN</h1>", unsafe_allow_html=True)
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>1. Th·ª±c hi·ªán content based fitering v√† Project design</h3>", unsafe_allow_html=True)
    st.image('picture/content_based_fitering.png')
    st.write(" ")

    st.markdown("<h3 style='text-align: left; color: Aqua;'>2. Th·ª±c hi·ªán Collaborative filtering v√† Project design</h3>", unsafe_allow_html=True)
    st.image('picture/Collaborative_filtering.png')
    st.write(" ")

elif choice == 'ƒê·∫ø xu·∫•t d·ª±a tr√™n n·ªôi dung':
    st.image('picture/tiki2.PNG')
    st.markdown("<h3 style='text-align: center; color: Coral;'>RECOMMENDATION SYSTEM BY BIG TEAM</h3>", unsafe_allow_html=True)
    st.write(" ")
    selected_movie = st.selectbox('Ch·ªçn s·∫£n ph·∫©m ƒëi n√†o b·∫°n',(list(data_content.fea_name.values)))
    df_recommnend = recommend(selected_movie)
    if st.button("H√£y nh·∫•n v√†o t√¥i ƒëi n√†o ü§°"):
        st.markdown("<h3 style='text-align: left; color: Aqua;'>B·∫¢NG S·∫¢N PH·∫®M</h3>", unsafe_allow_html=True)
        df_recommnend.reset_index()
        product_img = df_recommnend['image'].tolist()
        #for i in range(1,len(df_recommnend.Names.values[:5])):
        # get movie id and movie title
        item_id = df_recommnend['id'][0]
        item_name = df_recommnend['Names'][0]
        product_img_1 = product_img[0]
        col11,col12 = st.columns(2)
        with col11:
            st.markdown('![Foo]('+product_img[0]+')')
        with col12:
            st.subheader("TITLE: " + selected_movie.upper())
            st.write("BRAND: " + df_recommnend['brand'][0]) 
            st.write("VOTES: " + str(df_recommnend['rating'][0]))
            st.write("PRICE: " + "{:0,}".format(float(df_recommnend['price'][0]))+" VNƒê")
        
        st.header("Recommendations")
        col1,col2 = st.columns(2)
        col4,col5 = st.columns(2)
        col6,col7 = st.columns(2)
        
        columns = [col1,col2,col4,col5,col6,col7]
        for i in range(len(columns)):
            with columns[i]:
                st.markdown('![Foo]('+product_img[i]+')')
                st.write(df_recommnend['Names'][i].upper())
                st.write("VOTES: " + str(df_recommnend['rating'][i]))
                st.write("BRAND: " + df_recommnend['brand'][i]) 
                st.write("PRICE: " + "{:0,}".format(float(df_recommnend['price'][i]))+" VNƒê")
                st.markdown("[Website]("+df_recommnend['url'][i]+")")
    
        st.markdown("<h3 style='text-align: left; color: Aqua;'>HI·ªÜN TH·ªä B·∫¢NG D·ªÆ LI·ªÜU</h3>", unsafe_allow_html=True)
        test = df_recommnend.astype(str)
        st.dataframe(test)
    
elif choice == 'ƒê·ªÅ xu·∫•t d·ª±a tr√™n s·∫£n ph·∫©m':
    st.image('picture/tiki2.PNG')
    #st.markdown("<h3 style='text-align: center; color: Coral;'>RECOMMENDATION SYSTEM BY BIG TEAM</h3>", unsafe_allow_html=True)
    #st.title("Movie Recommendation Engine")
    html_temp = """
    <div style="background-color:tomato;padding:10px">
    <h2 style="color:white;text-align:center;">Item Recommendation Engine App by Big team </h2>
    </div>
    """
    st.markdown(html_temp,unsafe_allow_html=True)
    test_user =st.text_input("Enter the User for whom you wanna see top 10 recommendationsÔºö",16762580)
    result=""
    
    if st.button("H√£y nh·∫•n v√†o t√¥i ƒëi n√†o ü§°"):
        data, rmse=pyspark_collaborative_filtering(test_user)
        product_img = data['image'].tolist()
        st.text('Top 10 items recommendations for user id'+' '+str(test_user)+' '+'are:')
        st.markdown("<h3 style='text-align: left; color: Aqua;'>HI·ªÜN TH·ªä B·∫¢NG D·ªÆ LI·ªÜU</h3>", unsafe_allow_html=True)
        st.write("RMSE = {}".format(round(rmse, 2)))
        test = data.astype(str)
        st.dataframe(test)

        st.write(" ")
        st.write(" ")
        st.write(" ")
        st.markdown("<h3 style='text-align: left; color: Aqua;'>S·∫¢N PH·∫®M ƒê·ªÄ XU·∫§T NG∆Ø·ªúI D√ôNG</h3>", unsafe_allow_html=True)

        col1,col2 = st.columns(2)
        col3,col4 = st.columns(2)
        col5,col6 = st.columns(2)
        col7,col8 = st.columns(2)
        col9,col10 = st.columns(2)
        
        columns = [col1,col2,col3,col4,col5,col6,col7,col8,col9,col10]
        
        for i in range(len(columns)):
            with columns[i]:
                #lst2 = ['fea_customer_id', 'prediction', 'fea_item_id','name','description', 'rating', 'price', 'list_price', 'brand','group', 'url', 'image' ]
                st.markdown('![Foo]('+product_img[i]+')')
                st.write(data['name'][i].upper())
                st.write("VOTES: " + str(data['rating'][i]))
                st.write("BRAND: " + data['brand'][i]) 
                st.write("PRICE: " + "{:0,}".format(float(data['price'][i]))+" VNƒê")
                st.markdown("[Website]("+data['url'][i]+")")

       
        

elif choice == 'K·∫øt lu·∫≠t v√† h∆∞·ªõng ph√°t tri·ªÉn h·ªá th·ªëng ƒë·ªÅ xu·∫•t':
    #st.image('picture/Ket_luan.jpg')
    st.markdown("<h1 style='text-align: center; color: Coral;'>K·∫æT LU·∫¨N V√Ä H∆Ø·ªöNG PH√ÅT TRI·ªÇN</h1>", unsafe_allow_html=True)
    st.markdown("<h3 style='text-align: left; color: Aqua;'>1. SWOT</h3>", unsafe_allow_html=True)
    st.write(" ")
    st.image('picture/SWOT.png')
    
    st.markdown("<h3 style='text-align: left; color: Aqua;'>2. T√†i li·ªáu tham kh·∫£o</h3>", unsafe_allow_html=True)
    st.markdown("http://www.salemmarafi.com/code/collaborative-filtering-with-python/")
    st.markdown("https://www.mapr.com/blog/inside-look-at-components-of-recommendation-engine")
    st.markdown("Book: Pyspark of Wenqiang Feng")
    st.markdown("Book: Machine Learning with PySpark With Natural Language Processing and Recommender Systems by Pramod Singh (z-lib.org)")
    st.markdown("Book: User Factors in Recommender Systems_ Case Studies in e-Commerce, News Recommending, and ... ( PDFDrive )")
    